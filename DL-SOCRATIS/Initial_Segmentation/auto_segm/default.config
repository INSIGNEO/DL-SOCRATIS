[Solver of Optimization]

	ram = GPU  					#CPU or GPU processes.
	ngpu = 2            				#Number of GPU processors (keras at most 8).
	optimizer = adam 				#Type of loss optimizer
	metrics = accuracy 				#Images input shape
	metrics1 = dice 				#Images input shape
	metrics2 = jaccard 				#Images input shape
	batch_size = 17 					#Batch size of train.
	batch_size_test = 10 				#Batch size of test.
	epochs =  10  					#Epochs of analysis.
	num_cores =  4 					#Numer of cores.
	store_results =  on				# (on,off) Store in txt all the mean and SD of each image if a big data set does not regomented.
	validation = off 				#If the data split with validation data
	validation_split=0.4				#The rate of validation data
					



[Path]

	store_txt= /home/michail/Desktop/PHD_BASIC_WORK_FILES/PHD/case_study/scedule_work/feasibility_of_project/SEGMENTATION_PIPELINE/CODE/Initial_segmentation/Initial_segmentation_Keras/code/python_source/Model 					#Path of store models, solvers.
	store_data_test= /home/michail/Desktop/PHD_BASIC_WORK_FILES/PHD/case_study/scedule_work/feasibility_of_project/SEGMENTATION_PIPELINE/CODE/Initial_segmentation/Initial_segmentation_Keras/code/python_source/Data 					#Path of store models, solvers.
	datapath=  /home/michail/Desktop/PHD_BASIC_WORK_FILES/PHD/case_study/scedule_work/feasibility_of_project/SEGMENTATION_PIPELINE/CODE/Initial_segmentation/Initial_segmentation_Keras/code/python_source/Data/Input    				#Root of images-labels for segmentation.




[Data]

	#pre dataset

	counter_extention_pre = txt 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention_pre  =  dcm 			#Write the extention of image txt, vtk ,jpeg.
	image_shape_pre  =   256 			#images input shape
	original_image_shape_pre  =  256      		#Original shape of images.
	roi_shape_pre  = 32    				#Shape of the ROI image
	pretrain_window = 11    			#Shape of window for the pre-train ROI image
	
	#roi dataset

	counter_extention_roi = txt 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention_roi  = dcm  			#Write the extention of image txt, vtk ,jpeg.
	image_shape_roi =  64 				#images input shape
	original_image_shape_roi  = 256			#Original shape of images.
	roi_shape_roi = 32    				#Shape of the ROI image
	
	#main dataset

	counter_extention = txt 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention = jpeg 				#Write the extention of image txt, vtk ,jpeg.
	image_shape = 128 				#images input shape
	original_image_shape =  128     		#Original shape of images.
	roi_shape = 128    				#Shape of the ROI image




[Data Augmentation]

	data_augm = True				#Data augmentation true or false.                       
	rotation_range = 180    			#Rotation range (0-180 degrees).
	width_shift_range = 0.1    			#Width shift range, as a float fraction of the width.
	height_shift_range = 0.1    			#Height shift range, as a float fraction of the height.
	zca_whitening = True 				#Apply ZCA whitening.
	featurewise_center = True 			#Set input mean to 0 over the dataset.
	samplewise_center = False 			#Set each sample mean to 0.
	featurewise_std_normalization = True 		#Divide inputs by std of the dataset.
	samplewise_std_normalization  = False 		#Divide each input by its std.
	horizontal_flip  = True 			#Randomly flip images.
	vertical_flip = True 				#Randomly flip images.
	zoom_range = 0.05   				#Amount of zoom. If a scalar z, zoom in [1-z, 1+z]. Can also pass a pair of floats as the zoom range.
	fill_mode = nearest 				#Points outside boundaries are filled according to mode: constant, nearest, reflect, or wrap.
	alpha = 500    				#Random elastic distortion: magnitude of distortion.
	sigma = 20     				#Random elastic distortion: length scale.
	normalize = False 				#Subtract mean and divide by std dev from each image.
	max_loops = 2                                   #The loop of augmented data that will be created
	shuffle = True					#Shuffle images in each epoch


[Model net]

	load_weights=                                   #Model weights to initialize training.
	loss_weights=                                   #When using dice or jaccard loss, how much to weight each output class.
	#roi

	roi_model = deep_conv    			#Roi model of analysis.
	roi_activation=relu    				#Kind of activation of net.	
	loss_roi= customized_loss 			#Loss type	
	pre_optimizer= Adam    				#pre optimizer.
	roi_optimizer= Adam    				#roi optimizer.
	roi_learning_rate = 				# Depengs the optimization algorithm
	roi_momentum =					# Depengs the optimization algorithm
	roi_decay = 					# Depengs the optimization algorithm
	roi_seed = 					# Depengs the optimization algorithm

	#main

	main_model = u_net 				#Main model of analysis.
	main_activation = relu 				#activation of main of unet.
	loss_main = customized_loss 			#Loss type.	
	optimizer = Adam 				#main-roi optimizer.	
	height = 128    				#height of unet.
	width = 128 	   				#width of unet.
	classes = 1    					#classes of unet.
	features = 64    				#Input size of features of unet.
	depth = 4    					#Depth of unet.	
	channels = 1    				#channels of unet RGB=3 Grey=1 unet.
	dropout = 0.0    				#Dropout of unet.
	batchnorm = False   				#Batch normalization of unet.	
	padding = valid     				#Padding of unet.
	learning_rate = 				# Depengs the optimization algorithm
	momentum = 					# Depengs the optimization algorithm
	decay =						# Depengs the optimization algorithm
	seed =						# Depengs the optimization algorithm


