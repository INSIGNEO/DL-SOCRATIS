
[Solver of Optimization]

	ram = CPU  					#CPU or GPU processes.
	ngpu = 4            				#Number of GPU processors (keras at most 8).
	metrics = log_jaccard 				#Images input shape
	metrics1 = log_dice  				#Images input shape
	metrics2 =  dice				#Images input shape
	batch_size = 1 				#Batch size of train.
	batch_size_test = 1 				#Batch size of test.
	epochs_pre =  16  				#Epochs of pre analysis.
	epochs_roi =  16  				#Epochs of roi analysis.
	epochs_main = 50  				#Epochs of main analysis.
	num_cores =  2 					#Numer of cores.
	store_results =  on				# (on,off) Store in txt all the mean and SD of each image if a big data set does not regomented.
	validation = off 				#If the data split with validation data
	validation_split=0.4				#The rate of validation data
	crossval_cycle= 4 				#Numerber of cycle of cross validation.
	early_stop= False                               #Use the early stop analysis.
	monitor_callbacks= loss                         #Callbacks save metric acc, loss, val_loss, val_acc.
	mode_convert= min       			#Callbacks mode convert max, min, auto.
	gan_synthetic= False 				#Gan synthtetic images.
	num_synthetic_images= 100 			#Number of synthetic images.
	fft_convert_data=off				#Convert data set to fft image.
[Path]

	store_txt=/home/michail/Desktop/PHD_BASIC_WORK_FILES/PHD/case_study/scedule_work/feasibility_of_project/SEGMENTATION_PIPELINE/CODE_generalization/Initial_Segmentation/Model							#Path of store models, solvers.
	store_data_test=/home/michail/Desktop/PHD_BASIC_WORK_FILES/PHD/case_study/scedule_work/feasibility_of_project/SEGMENTATION_PIPELINE/CODE_generalization/data_internal/Data/ED 								#Path of store models, solvers.
	datapath=/home/michail/Desktop/PHD_BASIC_WORK_FILES/PHD/case_study/scedule_work/feasibility_of_project/SEGMENTATION_PIPELINE/CODE_generalization/data_internal/Input/image_ED  								#Root of images-labels for segmentation.
	gan_train_directory=               		#Root of Gan synthetic images.


[Data]

	patient_list = roi.json 			#dataset .json file the name of patient list
	patient_store_style= use			#Its the way the data of patient's mask and dcm are stored choices: MICCAI_2009, MICCAI_2017, use( mask and dcm in the same path of the specific patient see example in the /Data/ROI path 
	
	#MICCAI_2009_parameters

	label_case_extension_1= 			#Write the extention of the contour label here i for endo o for epi cardium.
	label_case_extension_2=				#Write the extention of the contour label here i for endo o for epi cardium.
	label_classes= 	first				#define the number of classes to simulate both: i, one: only i, two: only o.
	
	#pre dataset

	counter_extention_pre = jpeg			#Write the extention of counter txt, vtk ,jpeg.
	data_extention_pre  = dcm				#Write the extention of image txt, vtk ,jpeg.
	image_shape_pre  =   				#images input shape
	original_image_shape_pre  =        		#Original shape of images.
	roi_shape_pre  =    				#Shape of the ROI image
	pretrain_window =    				#Shape of window for the pre-train ROI image
	
	#roi dataset

	counter_extention_roi = jpeg 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention_roi  = dcm			#Write the extention of image txt, vtk ,jpeg.
	image_shape_roi =  64 				#images input shape
	original_image_shape_roi  = 256			#Original shape of images.
	roi_shape_roi = 32    				#Shape of the ROI image
	
	#main dataset

	counter_extention = jpeg 			#Write the extention of counter txt, vtk ,jpeg.
	data_extention = jpeg 				#Write the extention of image txt, vtk ,jpeg.
	image_shape = 284 				#images input shape
	original_image_shape =  284     		#Original shape of images.
	roi_shape = 196    				#Shape of the ROI image
	restore_image = off    				#Run the main simulation base the stored image in data_extention choice.



[Data Augmentation]

	data_augm =False				#Data augmentation classic, elastic deformation, or noise true or false
	random_apply_in_batch =  			#Apply random the Data augmentation in each batch true or false.
	data_augm_classic =False				#Data augmentation classic true or false.                       
	rotation_range =     				#Rotation range (0-180 degrees).
	width_shift_range =     			#Width shift range, as a float fraction of the width.
	height_shift_range =     			#Height shift range, as a float fraction of the height.
	zca_whitening =  				#Apply ZCA whitening.
	featurewise_center =  				#Set input mean to 0 over the dataset.
	samplewise_center =  				#Set each sample mean to 0.
	featurewise_std_normalization =  		#Divide inputs by std of the dataset.
	samplewise_std_normalization  =  		#Divide each input by its std.
	horizontal_flip  = 				#Randomly flip images.
	vertical_flip = 				#Randomly flip images.
	zoom_range =    				#Amount of zoom. If a scalar z, zoom in [1-z, 1+z]. Can also pass a pair of floats as the zoom range.
	fill_mode =  					#Points outside boundaries are filled according to mode: constant, nearest, reflect, or wrap.
	alpha =     					#Random elastic distortion: magnitude of distortion.
	sigma =      					#Random elastic distortion: length scale.
	normalize = True 				#Subtract mean and divide by std dev from each image.
	max_loops =                                     #The loop of augmented data that will be created
	shuffle = False					#Shuffle images in each epoch
	noise=False					#Add salt and peper noise to image

[Model net]

	load_weights_roi=                               #Model roi weights to initialize training( /Model dir`).
	load_weights_main=                              #Model main weights to initialize training( /Model dir`).
	loss_weights=                         		#When using dice or jaccard loss, how much to weight each output class.

	#roi

	roi_model = deep_conv    			#Roi model of analysis.
	roi_activation=    				#Kind of activation of net.	
	loss_pre= 					#Loss type	
	loss_roi=  					#Loss type	
	pre_optimizer=     				#pre optimizer.
	roi_optimizer=     				#roi optimizer.
	roi_learning_rate =				# Depengs the optimization algorithm
	roi_momentum =					# Depengs the optimization algorithm
	roi_decay =					# Depengs the optimization algorithm
	roi_seed =					# Depengs the optimization algorithm

	#main

	main_model = u_net 				#Main model of analysis.
	max_norm_const =    				#U-net parameter of constarin max norm on, off.
	max_norm_value =     				#U-net parameter of constarin max norm value.
	main_activation = 				#activation of main of unet.
	loss_main =  					#Loss type.	
	m_optimizer = 					#Optimizer: sgd, rmsprop, adagrad, adadelta, adam, adamax, or nadam..	
	height = 284   					#height of unet.
	width = 284	   				#width of unet.
	classes =   					#classes of unet.
	features = 128   					#Input size of features of unet.
	depth =   3  					#Depth of unet.	
	channels =     					#channels of unet RGB=3 Grey=1 unet.
	dropout =    					#Dropout of unet.
	batchnorm =   					#Batch normalization of unet.	
	padding =     					#Padding of unet.
	learning_rate = 				# Depengs the optimization algorithm
	momentum =					# Depengs the optimization algorithm
	decay =						# Depengs the optimization algorithm
	seed =						# Depengs the optimization algorithm


